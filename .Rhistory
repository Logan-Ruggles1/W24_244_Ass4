library(factoextra)
library(dendextend)
library(ggdendro)
var_names <- c('a', 'p', 'c', 'l_k', 'w_k', 'asym', 'l_g', 'variety')
seeds_df <- read_tsv(here::here('data/seeds_dataset.txt'),
col_names = FALSE,
na = '-999') %>%
setNames(var_names) %>%
mutate(variety = case_when(variety == 1 ~ 'Kama',
variety == 2 ~ 'Rosa',
variety == 3 ~ 'Canadian',
TRUE ~ 'oops'))
### or names(seeds_df) <- var_names
summary(seeds_df)
seeds_df_long <- seeds_df %>%
pivot_longer(cols = -variety)
ggplot(seeds_df_long, aes(x = value)) +
geom_histogram() +
facet_grid(variety ~ name, scales = 'free')
ggplot(seeds_df) +
geom_point(aes(x = a, y = asym, color = c, shape = variety),
size = 3, alpha = 0.7)
# try other variations:
ggplot(seeds_df) +
geom_point(aes(x = l_g, y = w_k, color = asym, shape = variety),
size = 3, alpha = 0.7)
# Drop rows where any of the measurements are missing
seeds_complete <- seeds_df %>%
drop_na()
# Only keep the columns for the measurements, then SCALE them
seeds_scale <- seeds_complete %>%
select(-variety) %>%
scale() # See ?scale for details on scaling
# compare scaled to original vars
summary(seeds_complete)
summary(seeds_scale)
# How many clusters do you THINK there should be?
number_est <- NbClust(seeds_scale, min.nc = 2, max.nc = 10, method = "kmeans")
# Check out the results (just look at the first summary report):
number_est
# By these estimators, 3 is identified as the best number of clusters by the largest number of algorithms (11 / 23)...  could we override this?  here I think it makes sense to stick with 3 (a cluster for each variety) and see how it does.
### knee method
fviz_nbclust(seeds_scale, FUNcluster = kmeans, method = 'wss', k.max = 10)
set.seed(10101)
seeds_km <- kmeans(seeds_scale, 3, nstart = 25) # kmeans specifying 3 groups to start
# See what it returns (different elements returned by kmeans function):
seeds_km$size # How many observations assigned to each cluster
seeds_km$cluster # What cluster each observation in seeds_scale is assigned to
# Bind the cluster number to the original data used for clustering, so that we can see what cluster each variety is assigned to
seeds_cl <- data.frame(seeds_complete,
cluster_no = factor(seeds_km$cluster))
### On your own:
### Plot area and asymmetric index, and include cluster number and variety for comparison:
ggplot(seeds_cl) +
geom_point(aes(x = a, y = asym, color = cluster_no, shape = variety),
size = 2)
### how well does this clustering match up to variety?  Select the variety and
### cluster number vars and make into a continency table
seeds_cl %>% select(variety, cluster_no) %>% table()
seeds_dist <- dist(seeds_scale, method = 'euclidean') ### look at upper and diag arguments
# Hierarchical clustering (complete linkage)
seeds_hc_complete <- hclust(seeds_dist, method = "complete")
# Plot it (base plot):
plot(seeds_hc_complete, cex = 0.6, hang = -1)
# use cutree to slice it into three clusters
seeds_cut_hc <- cutree(seeds_hc_complete, 3)
table(seeds_cut_hc, seeds_complete$variety)
# Get the data
wb_env <- read_csv(here::here("data/wb_env.csv"))
# Make sure to take a look at the data:
# View(wb_env)
# Only keep top 20 greenhouse gas emitters (for simplifying visualization here...)
wb_ghg_20 <- wb_env %>%
slice_max(ghg, n = 20)
summary(wb_ghg_20)
# Scale the numeric variables (columns 3:7)
wb_scaled <- wb_ghg_20 %>%
select(3:7) %>%
scale()
summary(wb_scaled)
# Update to add rownames (country name) from wb_ghg_20
rownames(wb_scaled) <- wb_ghg_20$name
# Check the outcome with View(wb_scaled) - see that the rownames are now the country name (this is useful for visualizing)
# Compute dissimilarity values (Euclidean distances):
euc_distance <- dist(wb_scaled, method = "euclidean") ### add diag and upper
# Check out the output:
# euc_distance
# Hierarchical clustering (complete linkage)
hc_complete <- hclust(euc_distance, method = "complete" )
# Plot it (base plot):
plot(hc_complete, cex = 0.6, hang = -1)
# Hierarchical clustering (single linkage)
hc_single <- hclust(euc_distance, method = "single" )
# Plot it (base plot):
plot(hc_single, cex = 0.6, hang = -1)
# Convert to class dendrogram
dend_complete <- as.dendrogram(hc_complete)
dend_simple <- as.dendrogram(hc_single)
# Make a tanglegram
tanglegram(dend_complete, dend_simple)
entanglement(dend_complete, dend_simple) # lower is better
#> [1] 0.3959222
untangle(dend_complete, dend_simple, method = "step1side") %>%
entanglement()
# [1] 0.06415907
untangle(dend_complete, dend_simple, method = "step1side") %>%
tanglegram(common_subtrees_color_branches = TRUE)
ggdendrogram(hc_complete,
rotate = TRUE) +
theme_minimal() +
labs(x = "Country")
# COOL. Then you can customize w/ usual ggplot tools.
library(tidyverse)
library(janitor)
library(here)
library(sf)
library(lubridate)
library(ggfortify) # For PCA biplot
library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)
chem_df <- read_csv(here('chem.csv')) %>%
janitor::clean_names()
setwd("~/Bren/W24/244_Adv_Data/Github/Ass4")
chem_df <- read_csv(here('chem.csv')) %>%
janitor::clean_names()
chem_df <- read_csv(here('chem.csv')) %>%
janitor::clean_names()
library(tidyverse)
library(janitor)
library(here)
library(sf)
library(lubridate)
library(ggfortify) # For PCA biplot
library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)
chem_df <- read_csv(here('chem.csv')) %>%
janitor::clean_names()
View(chem_df)
summary(chem_df)
chem_long <- chem_df %>%
pivot_longer(cols = -c(site_code, timestamp_local))
View(chem_long)
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
ggplot(chem_long, aes(x = value)) +
geom_histogram()
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
chem_long <- chem_df %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local)
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
library(dplyr)
chem_avg <- chem_df %>%
group_by(site_code) %>%
summarize(mean = mean(outcome))
chem_avg <- chem_df %>%
group_by(name) %>%
summarize(mean = mean(value))
chem_avg <- chem_long %>%
group_by(name) %>%
summarize(mean = mean(value))
View(chem_avg)
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names()
View(chem_df)
summary(chem_df)
chem_6 <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
View(chem_6)
View(chem_6)
chem_long <- chem_6 %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
# ggplot(chem_long, aes(x = value)) +
#   geom_histogram() +
#   facet_grid(site_code ~ name, scales = 'free')
# would prefer to do this with averages
View(chem_long)
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
#summary(chem_df)
count(chem_df$site_code)
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names() %>%
mutate(site_code = as.factor(site_code))
#summary(chem_df)
count(chem_df$site_code)
#summary(chem_df)
summarise(chem_df$site_code)
#summary(chem_df)
summary(chem_df$site_code)
n_distinct(chem_df$site_code)
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names() %>%
#summary(chem_df)
#19,390 obs, 10/23/2000 to 7/28/2018
# n_distinct(chem_df$site_code) # 13 site codes
```
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names()
#summary(chem_df)
#19,390 obs, 10/23/2000 to 7/28/2018
n_distinct(chem_df$site_code) # 13 site codes
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name)
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names()
#summary(chem_df)
#19,390 obs, 10/23/2000 to 7/28/2018
n_distinct(chem_df$site_code) # 13 site codes
chem_6 <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
chem_long <- chem_6 %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name)
# would prefer to do this with averages
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
chem_avg <- chem_long %>%
group_by(name) %>%
summarize(mean = mean(value))
View(chem_avg)
chem_NAs <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
chem_NAs <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
chem_NA <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
chem_long <- chem_NA %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
# would prefer to do this with averages
chem_no_NAs <- chem_df %>%
drop_na()
View(chem_no_NAs)
n_distinct(chem_no_NAs$site_code)
chem_no_NA <- chem_df %>%
drop_na()
n_distinct(chem_no_NA$site_code) #6 sites
n_distinct(chem_NA$site_code)
chem_long <- chem_no_NA %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
# would prefer to do this with averages
chem_avg <- chem_long %>%
group_by(name) %>%
summarize(mean = mean(value))
chem_avg <- chem_long %>%
group_by(name)
View(chem_avg)
chem_avg <- chem_long %>%
group_by(site_code)
View(chem_avg)
chem_avg <- chem_long %>%
group_by(site_code) %>%
summarize(mean = mean(value))
View(chem_avg)
group_split(chem_avg)
chem_avg <- chem_long %>%
group_by(site_code)
group_split(chem_avg)
chem_avg <- chem_long %>%
group_split(chem_avg)
group_split(chem_avg)
group_split(site_code)
sites <- chem_avg %>%
group_split(site_code)
gs <- group_split(chem_avg)
sites <- group_split(chem_avg)
View(sites)
names(sites) <- 1:length(sites)
View(sites)
write_csv(sites[[i]], file = paste0(names(sites)[i], ".csv"))
View(sites)
RG01 <- chem_long %>%
filter(site_code == "RG01")
View(RG01)
RG01 <- chem_long %>%
filter(site_code == "RG01")
RG01 <- chem_long %>%
filter(site_code == "ON02")
RG01 <- chem_long %>%
filter(site_code == "MC06")
RG01 <- chem_long %>%
filter(site_code == "MC00")
RG01 <- chem_long %>%
filter(site_code == "GV01")
RG01 <- chem_long %>%
filter(site_code == "AB00")
RG01 <- chem_long %>%
filter(site_code == "RG01")
ON02 <- chem_long %>%
filter(site_code == "ON02")
MC06 <- chem_long %>%
filter(site_code == "MC06")
MC00 <- chem_long %>%
filter(site_code == "MC00")
GV01 <- chem_long %>%
filter(site_code == "GV01")
AB00 <- chem_long %>%
filter(site_code == "AB00")
View(ON02)
chem_avg <- chem_long %>%
group_by(site_code) %>%
summarise(mean = mean(value))
View(chem_avg)
chem_avg <- chem_long %>%
group_by(site_code)
RG01_avg <- RG01 %>%
summarise(mean = mean(value))
View(RG01_avg)
View(chem_NA)
View(chem_NAs)
View(chem_long)
RG01_avg <- RG01 %>%
group_by(name)
View(RG01_avg)
RG01_avg <- RG01 %>%
group_by(name) %>%
summarise(mean = mean(value))
View(RG01_avg)
chem_long <- chem_no_NA %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
chem_avg <- chem_long %>%
group_by(site_code)
sites <- group_split(chem_avg)
RG01 <- chem_long %>%
filter(site_code == "RG01")
RG01 <- chem_long %>%
filter(site_code == "RG01")
ON02 <- chem_long %>%
filter(site_code == "ON02")
MC06 <- chem_long %>%
filter(site_code == "MC06")
MC00 <- chem_long %>%
filter(site_code == "MC00")
GV01 <- chem_long %>%
filter(site_code == "GV01")
AB00 <- chem_long %>%
filter(site_code == "AB00")
RG01_avg <- RG01 %>%
group_by(name) %>%
summarise(mean = mean(value))
View(RG01_avg)
library(tidyverse)
library(janitor)
library(here)
library(dplyr)
library(lubridate)
library(ggfortify) # For PCA biplot
library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)
library(patchwork)
library(cowplot)
#matrix?
library(purrr)
library(tidymodels)
library(broom)
library(kableExtra)
library(Metrics)
chem_df <- read_csv(here('chem.csv'),
na = '-999') %>%
janitor::clean_names()
#summary(chem_df)
#19,390 obs, 10/23/2000 to 7/28/2018
n_distinct(chem_df$site_code) # 13 site codes
chem_NA <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter))
n_distinct(chem_NA$site_code) #13 sites
chem_no_NA <- chem_df %>%
select(-c(tpc_u_m, tpn_u_m, tpp_u_m, tss_mgper_liter)) %>%
drop_na()
n_distinct(chem_no_NA$site_code) #6 sites
chem_long <- chem_no_NA %>%
pivot_longer(cols = -c(site_code, timestamp_local)) %>%
select(-timestamp_local) #don't need timestamp for this analysis
ggplot(chem_long, aes(x = value)) +
geom_histogram() +
facet_grid(site_code ~ name, scales = 'free')
# would prefer to do this with averages
# want to create a new df where take mean of each non-"site_code" variable for each site_code. Column 1 site_code, names specific_variable_avg, values avg of variable by site
# make matrix to separate sites?
chem_avg <- chem_long %>%
group_by(site_code)
# need to do a double group by basically
# sites <- group_split(chem_avg)
#
# names(sites) <- 1:length(sites)
#
# for(i in 1:length(sites)){
#   write_csv(sites[[i]], file = paste0(names(sites)[i], ".csv"))
# }
#Error in `[[.vctrs_list_of`(sites, i) : object 'i' not found
RG01 <- chem_long %>%
filter(site_code == "RG01")
ON02 <- chem_long %>%
filter(site_code == "ON02")
MC06 <- chem_long %>%
filter(site_code == "MC06")
MC00 <- chem_long %>%
filter(site_code == "MC00")
GV01 <- chem_long %>%
filter(site_code == "GV01")
AB00 <- chem_long %>%
filter(site_code == "AB00")
RG01_avg <- RG01 %>%
group_by(name) %>%
summarise(mean = mean(value))
# not the 6 variables
# rmse_map_list <- purrr::map(.x = 1:folds, .f = kfold_cv,
#                             ### our function needs two more arguments:
#                             df = penguins_fold, formula = f1)
# rmse_map_vec <- unlist(rmse_map_list)
# mean(rmse_map_vec)
#
# ### OR we know the output is a double (a non-integer number)
# rmse_map_vec <- map_dbl(.x = 1:folds, .f = kfold_cv,
#                         ### our function needs two more arguments:
#                         df = penguins_fold, formula = f1)
# mean(rmse_map_vec)
# rmse_df <- data.frame(j = 1:folds) %>%
#   mutate(rmse_mdl1 = map_dbl(j, kfold_cv, df = penguins_fold, formula = f1),
#          rmse_mdl2 = map_dbl(j, kfold_cv, df = penguins_fold, formula = f2),
#          rmse_mdl3 = map_dbl(j, kfold_cv, df = penguins_fold, formula = f3))
#
# rmse_means <- rmse_df %>%
#   summarize(across(starts_with('rmse'), mean))
View(RG01_avg)
View(RG01_avg)
RG01_avg <- RG01 %>%
group_by(name) %>%
summarise(mean = mean(value))
ON02_avg <- ON02 %>%
group_by(name) %>%
summarise(mean = mean(value))
MC06_avg <- MC06 %>%
group_by(name) %>%
summarise(mean = mean(value))
MC00_avg <- MC00 %>%
group_by(name) %>%
summarise(mean = mean(value))
GV01_avg <- GV01 %>%
group_by(name) %>%
summarise(mean = mean(value))
AB00_avg <- AB00 %>%
group_by(name) %>%
summarise(mean = mean(value))
View(MC06_avg)
site_avg_wide <- full_join(RG01_avg, ON02)
View(RG01_avg)
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean)
View(RG01_avg_wide)
RG01_avg_wide <- RG01_avg %>%
paste(colnames(RG01_avg), "avg", sep = "_") %>%
pivot_wider(names_from = name, values_from = mean) %>%
paste()
RG01_avg_wide <- RG01_avg %>%
paste(colnames(RG01_avg), "avg", sep = "_")
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean) %>%
paste(colnames(), "avg", sep = "_")
paste(colnames(RG01_avg_wide), "avg", sep = "_")
View(RG01_avg)
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean)
paste(colnames(RG01_avg_wide), "avg", sep = "_")
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean) %>%
rename_with( ~ paste0(.x, "_avg"))
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean) %>%
rename_with( ~ paste0(.x, "_avg"))
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean)
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean)
RG01_avg_wide <- RG01_avg %>%
pivot_wider(names_from = name, values_from = mean) %>%
rename_with( ~ paste0(.x, "_avg"))
